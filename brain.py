# brain.py
"""
Brain module for the DeepSeek Telegram bot.
Handles decision-making and response generation using DeepSeek API.
"""

import logging
import random
from typing import Optional

from openai import OpenAI

import config

logger = logging.getLogger(__name__)


class Brain:
    """
    AI logic for the bot using DeepSeek API.
    Makes decisions about when to respond and generates responses.
    """

    SYSTEM_PROMPT = f"""–¢—ã {config.BOT_NAME} - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –±–æ—Ç-—É—á–∞—Å—Ç–Ω–∏–∫ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ —á–∞—Ç–∞. –¢—ã –≥–æ–≤–æ—Ä–∏—à—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ —Å –¥—Ä—É–∑—å—è–º–∏.

–•–∞—Ä–∞–∫—Ç–µ—Ä:
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –Ω–µ–º–Ω–æ–≥–æ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π
- –ò–Ω—Ç–µ—Ä–µ—Å—É–µ—à—å—Å—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º–∏ –≤ —á–∞—Ç–µ
- –õ—é–±–∏—à—å —à—É—Ç–∫–∏ –∏ –º–µ–º—ã
- –ú–∞–ª–µ–Ω—å–∫–∏–º–∏ –±—É–∫–≤–∞–º–∏, –º–æ–∂–Ω–æ –±–µ–∑ —Ç–æ—á–µ–∫ –≤ –∫–æ–Ω—Ü–µ
- –ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–Ω–≥ (–∫–µ–∫, –ª–æ–ª, –∏–º—Ö–æ, –Ω–æ—Ä–º, –∑–±—Å –∏ —Ç–ø)
- –ù–∏–∫–∞–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤ –∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã "–∫–∞–∫ AI —è..." –∏–ª–∏ "—è –Ω–µ –º–æ–≥—É..."

–§–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞ (–≤—ã–±–µ—Ä–∏ –û–î–ò–ù):
1. –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
2. "REACT:<—ç–º–æ–¥–∑–∏>" —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏ (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ)
3. "GIPHY:<–∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º>" –¥–ª—è –≥–∏—Ñ–∫–∏ (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ)
4. "STICKER:<—ç–º–æ—Ü–∏—è>" –¥–ª—è —Å—Ç–∏–∫–µ—Ä–∞ (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ)

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–∏–∫–µ—Ä—ã: happy, sad, laugh, cool, think, wtf

–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:
- "–∫—Ç–æ –∑–∞ –ø–∏—Ü—Ü—É —Å–µ–≥–æ–¥–Ω—è?" ‚Üí "—è –∑–∞"
- "–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –∫–∞–∫—É—é –º–∞—à–∏–Ω—É —É–≤–∏–¥–µ–ª" [—Ñ–æ—Ç–æ] ‚Üí "REACT:üî•"
- "–±–ª–∏–Ω —É—Ä–æ–Ω–∏–ª —Ç–µ–ª–µ—Ñ–æ–Ω –≤ —É–Ω–∏—Ç–∞–∑" ‚Üí "GIPHY:facepalm"
- "—Å–¥–∞–ª —ç–∫–∑–∞–º–µ–Ω –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ!" ‚Üí "STICKER:cool"
- "—á–µ –¥—É–º–∞–µ—Ç–µ –ø—Ä–æ –Ω–æ–≤—ã–π —Ñ–∏–ª—å–º?" ‚Üí "–Ω–µ —Å–º–æ—Ç—Ä–µ–ª –µ—â—ë, –æ–Ω –∑–∞—à—ë–ª?"
- "—Å–æ–≥–ª–∞—Å–Ω—ã?" ‚Üí "REACT:üëç"

–í–ê–ñ–ù–û:
- –ü–∏—à–∏ –ö–û–†–û–¢–ö–û (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
- –ù–µ –±–æ–ª–µ–µ 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ—Ç–≤–µ—Ç
"""

    def __init__(self):
        """Initialize DeepSeek API client."""
        try:
            self.client = OpenAI(
                api_key=config.DEEPSEEK_API_KEY,
                base_url=config.DEEPSEEK_BASE_URL
            )
            logger.info("Brain initialized: DeepSeek client ready")
        except Exception as e:
            logger.error(f"Failed to initialize Brain: {e}")
            raise

    def should_respond(self, message_text: str, recent_messages: list = None) -> bool:
        """
        Determine if the bot should respond to a message.
        
        Conditions:
        1. Message mentions bot name (case-insensitive)
        2. Message contains question mark "?"
        3. Random 10% chance on any message
        
        Args:
            message_text: The received message text
            recent_messages: List of recent messages (for context, unused for now)
        
        Returns:
            True if bot should respond, False otherwise
        """
        # Check if bot name is mentioned (case-insensitive)
        if config.BOT_NAME.lower() in message_text.lower():
            logger.info(f"Should respond: bot name mentioned in '{message_text[:50]}'")
            return True

        # Check if message contains question mark
        if "?" in message_text:
            logger.info(f"Should respond: question mark in '{message_text[:50]}'")
            return True

        # Random 10% chance on any message
        random_chance = random.random()
        if random_chance < config.RANDOM_RESPONSE_PROBABILITY:
            logger.info(f"Should respond: random chance ({random_chance:.2%}) in '{message_text[:50]}'")
            return True

        return False

    def generate_response(self, message_text: str, context: str) -> str:
        """
        Generate a response using DeepSeek API.
        
        Args:
            message_text: The current message to respond to
            context: Formatted recent messages as context
        
        Returns:
            Generated response text (may contain REACT:, GIPHY:, STICKER: prefixes)
        """
        try:
            # Prepare messages for API
            messages = [
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": f"""–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–µ:
{context}

–ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞: {message_text}"""
                }
            ]

            # Call DeepSeek API
            response = self.client.chat.completions.create(
                model=config.DEEPSEEK_MODEL,
                messages=messages,
                max_tokens=config.DEEPSEEK_MAX_TOKENS,
                temperature=config.DEEPSEEK_TEMPERATURE
            )

            # Extract response text
            answer = response.choices[0].message.content.strip()
            logger.info(f"Generated response: {answer[:50]}")
            return answer

        except Exception as e:
            logger.error(f"Error generating response from DeepSeek: {e}")
            return "–ë–∞–±–∫–∏ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å —Ç–∞–∫ —á—Ç–æ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ–ª—å—à–µ –Ω–µ –±—É–¥–µ—Ç."  # Fallback response
